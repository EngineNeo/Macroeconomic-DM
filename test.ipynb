{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stephen Bannon Reassures Conservatives Uneasy About Trump\n"
     ]
    }
   ],
   "source": [
    "from newsplease import NewsPlease\n",
    "article = NewsPlease.from_url('https://www.nytimes.com/2017/02/23/us/politics/cpac-stephen-bannon-reince-priebus.html?hp')\n",
    "print(article.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'date' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 71\u001b[0m\n\u001b[0;32m     68\u001b[0m start_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m timedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m365\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     69\u001b[0m end_date \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m---> 71\u001b[0m \u001b[43mfetch_and_filter_news\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 56\u001b[0m, in \u001b[0;36mfetch_and_filter_news\u001b[1;34m(start_date, end_date, batch_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m         content \u001b[38;5;241m=\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     55\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwriterow([date, headline, content])\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mdate\u001b[49m, headline, content)\n\u001b[0;32m     58\u001b[0m next_page_token \u001b[38;5;241m=\u001b[39m news_batch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_page_token\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     59\u001b[0m has_more \u001b[38;5;241m=\u001b[39m next_page_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'date' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set env variables\n",
    "APCA_API_KEY_ID = os.getenv(\"APCA_API_KEY_ID\")\n",
    "APCA_API_SECRET_KEY = os.getenv(\"APCA_API_SECRET_KEY\")\n",
    "\n",
    "# Keywords related to macroeconomic indicators\n",
    "keywords = [\n",
    "    \"Gross Domestic Product\", \"GDP\", \"Unemployment Rate\", \"Inflation Rate\",\n",
    "    \"Consumer Price Index\", \"CPI\", \"Producer Price Index\", \"PPI\", \"Interest Rates\",\n",
    "    \"Balance of Trade\", \"Government Debt\", \"Budget Deficit\", \"Surplus\", \"Exchange Rates\",\n",
    "    \"Money Supply\", \"Industrial Production\", \"Retail Sales\", \"Housing Starts\"\n",
    "]\n",
    "\n",
    "# Prepare headers for the HTTP request\n",
    "headers = {\n",
    "    'APCA-API-KEY-ID': APCA_API_KEY_ID,\n",
    "    'APCA-API-SECRET-KEY': APCA_API_SECRET_KEY,\n",
    "}\n",
    "\n",
    "# Fetch and filter news and write to csv\n",
    "def fetch_and_filter_news(start_date, end_date, batch_size=30):\n",
    "    next_page_token = None\n",
    "    has_more = True\n",
    "    with open('macroeconomic_news.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Date\", \"Headline\", \"Content\"])\n",
    "\n",
    "        while start_date < end_date:\n",
    "            batch_end_date = start_date + timedelta(days=30)\n",
    "            while has_more:\n",
    "                params = {\n",
    "                    'start': start_date.strftime('%Y-%m-%d'),\n",
    "                    'end': batch_end_date.strftime('%Y-%m-%d'),\n",
    "                    'include_content': 'true',\n",
    "                    'limit': batch_size,\n",
    "                }\n",
    "\n",
    "                if next_page_token:\n",
    "                    params['page_token'] = next_page_token\n",
    "\n",
    "                response = requests.get('https://data.alpaca.markets/v1beta1/news', headers=headers, params=params)\n",
    "\n",
    "                if response.status_code == 200:\n",
    "                    news_batch = response.json()\n",
    "                    for article in news_batch['news']:\n",
    "                        # Keyword check\n",
    "                        if any(keyword in article['headline'] or keyword in article['summary'] for keyword in keywords):\n",
    "                            date = datetime.fromisoformat(article['created_at']).strftime('%m/%d/%Y')\n",
    "                            headline = article['headline']\n",
    "                            content = article['summary']\n",
    "                            writer.writerow([date, headline, content])\n",
    "                            print(date, headline, content)\n",
    "\n",
    "                    next_page_token = news_batch.get('next_page_token')\n",
    "                    has_more = next_page_token is not None\n",
    "                    if not has_more:  # Reset for the next batch\n",
    "                        start_date += timedelta(days=30)  # Next 30 days\n",
    "                        next_page_token = None  # Reset pagination token\n",
    "                        has_more = True  # Reset has_more\n",
    "                else:\n",
    "                    print(\"Failed to fetch news articles\", response.status_code)\n",
    "                    break\n",
    "\n",
    "start_date = datetime.now() - timedelta(days=365*3)\n",
    "end_date = datetime.now()\n",
    "\n",
    "fetch_and_filter_news(start_date, end_date, batch_size=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webscraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
